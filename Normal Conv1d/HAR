# -*- coding: utf-8 -*-
"""HAR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YBIgTRykv4CqVEHZZfeqr1XZb8NTc9IE
"""



"""# Human Activity Recognition

Human activity recognition is the problem of classifying sequences of accelerometer data recorded by specialized harnesses or smart phones into known well-defined movements.

## Classical Approach

Our first step is extracting features from the raw data using feature engineering. We usually create sensor speicific or domain specific features and it requires an expert to analyze the data and engineer the feature required for the model.

Once the data is ready we can employ traditional machine learning models like SVM, KNN CLassifier, Random Forest, Gradient Bossting etc.

One of the major drawback of this approach was its need for an expert for engieerning the features for the model to fit. Moreover the features extracted will be sensor specific and domain speciific. 

We need to robust approach where the model or the preprocessing is itself able to understand these features and give us robust classification. This led to Neural Netwiork Architecture

## Neural Network
Neural Network are special class of machine learning algorithms that are inspired by biological neurons. 
Recently with the advent to huge amount data generated from accelerometer and gyroscope from  the mobile phone, Neural netoworks have started expanding in the field of Humna Activity Recognition and producing state-of-art results. They learn from raw sesor data and are producing better results from the models derived from classical approach.

We are going to discuss two major Neural Network Arcchitecute used for Human Activity
 Reocgnition-
 1. Convolutionlal Neural Network
 2. Recurrent Neurlal Network
 
 
 ### Convolutional Neural Network
 Although they are mostly used for understanding and analyziing images or video data. We can use 1D Convolutional Kernel to capture the dependecy of the senor data.
 
 *"CNN has two advantages over other models: local dependency and scale invariance. Local dependency means the nearby signals in HAR are likely to be correlated, while scale invariance refers to the scale-invariant for different paces or frequencies.""*

— Deep Learning for Sensor-based Activity Recognition: A Survey, 2018.


Following are few innovative and major papers used for Human Activiity Recognition-
1. [Convolutional Neural Networks for Human Activity Recognition using Mobile Sensors](https://ieeexplore.ieee.org/document/7026300)
2. [Divide and Conquer-Based 1D CNN Human Activity Recognition Using Test Data Sharpening.](http://www.mdpi.com/1424-8220/18/4/1055)
3. [Human Activity Recognition Using Wearable Sensors by Deep Convolutional Neural Networks.](https://dl.acm.org/citation.cfm?id=2806333)
 
 src([Deep Learning Models for Human Activity Recognition by Jason Brownlee](https://machinelearningmastery.com/deep-learning-models-for-human-activity-recognition/))
 
 
 Other than the 3rd paper all of them use Conv1D for analyzing the sequence, so we need to first unnderstand what is Conv1D and how does it work.
 
 
 ### Conv1D
  Convolutional 1D is a 1-dimension convolutinalm kernel that operates in similar fashion as in case ofd 2D convolution. It is usually used in analyzing sequence and capturing short term depedency in sequences. One major advantage it has over LSTM or any recurrent neural network is its mutifold better speed to train and test. Convolution 1D is also heavily used in Inception Network.
  
  Let's now get to coding....

Human Activity Recognition
Author :  Saurabh Khandelwal
"""

import pandas as pd #loading the csv data
import 	numpy as np
import matplotlib.pyplot as plt #visualization
import os
from keras.utils import to_categorical
from keras.models import Sequential
import keras

print ( " We are going to use the dataset provided in “A Public Domain Dataset for Human Activity Recognition Using Smartphones.”")
url_to_dataset = "https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones"

"""**Write text about how to load data into models
**
> Indented block
"""

"""
Function  : read_Txtfile
@Params: 
        filename - String - Name of the txt file we need to load
Return:
        return
"""

def read_Txtfile(filename):
  data = pd.read_csv(filename, header = None,delim_whitespace = True)
  return data.values

def read_DataGroup(prefix,group,filenames):
  data = []
  for filename in filenames:
    for file in filename:
      temp = read_Txtfile(prefix+'/'+file)
      data.append(temp)
  
  train_X = np.dstack(data)
  return train_X

def load_Data(prefix,group):
  path = prefix + '/' + group + '/Inertial Signals' 
  filenames = []
  filenames.append(['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt'])
  
  filenames.append(['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt'])
  
  filenames.append(['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt'])
  
  X_train =  read_DataGroup(path,group,filenames)
  y_train = read_Txtfile(prefix+'/'+group+'/'+ 'y_'+group+'.txt')
  
  print (np.array(X_train).shape)
  print (y_train.shape)
  return np.array(X_train), y_train

X_train,y_train = load_Data('/content','train')
X_test,y_test = load_Data('/content','test')

#We need one hot encode the y label
y_train-=1
y_test-=1
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

print ("Shape of y_train : ",y_train.shape)

print ("Shape of y_test : ",y_test.shape)

np.save('X_train',X_train)
np.save('X_test',X_test)
np.save('y_train',y_train)
np.save('y_test',y_test)

print ("Shape of y_train : ",y_train.shape)

print ("Shape of y_test : ",y_test.shape)

print ("Shape of X_train : ",X_train.shape)

print ("Shape of X_test : ",X_test.shape)

from keras.layers import Conv1D,MaxPooling1D, Dense, Flatten, Dropout

def model_Conv1D(n_timesteps,features):
  model = Sequential()
  model.add(Conv1D(filters = 64, kernel_size = 3, activation = 'relu', input_shape = (n_timesteps,features)))
  model.add(Conv1D(filters = 64, kernel_size = 3, activation = 'relu', input_shape = (n_timesteps,features)))
  model.add(Dropout(0.5))
  model.add(MaxPooling1D(pool_size = 2))
  model.add(Flatten())
#   model.add(Dense(128,activation = 'tanh'))
#   model.add(Dense(64,activation = 'tanh'))
  model.add(Dropout(0.1))
  model.add(Dense(32,activation = 'relu'))
  model.add(Dense(8,activation = 'relu'))
  model.add(Dense(6,activation = 'softmax'))
  
  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])
  
  print (model.summary())
  
  return model

checkpoint = keras.callbacks.ModelCheckpoint('model_{epoch:02d}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)
tensor_board = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')

model = model_Conv1D(X_train.shape[1],X_train.shape[2])
history = model.fit(X_train,y_train,epochs = 10,batch_size=32,verbose = 1,callbacks = [checkpoint,tensor_board])

model.evaluate(X_test,y_test)



from keras.layers import Conv1D,MaxPooling1D, Dense, Flatten, Dropout, Input
from keras.layers.merge import concatenate
from keras.models import Model
import pydot

"""We can play around with the kernel size and number of filters. I will lleave that to you. 

Let's try to go a step ahead and merge multiiple Conv1D models with different hyperparameters. We are going to use  keras.layers.merge.concatenate fuction for that.
"""

def multi_headed_Models(kernel_size,filter_no,n_timesteps,features):
  verbose = 1
  epochs = 10
  batch_size = 32
  
  inp = Input(shape = (n_timesteps,features))
  conv11 = Conv1D(filter_no[0],kernel_size[0],activation = 'relu')(inp)
  conv12 = Conv1D(filter_no[0], kernel_size[0], activation = 'relu')(conv11)
  drop1 = Dropout(0.5)(conv12)
  pool1 = MaxPooling1D(pool_size = 2)(drop1)
  flat1 =  Flatten()(pool1)
  
  conv21 = Conv1D(filter_no[1],kernel_size[1],activation = 'relu')(inp)
  conv22 = Conv1D(filter_no[1], kernel_size[1], activation = 'relu')(conv21)
  drop2 = Dropout(0.5)(conv22)
  pool2 = MaxPooling1D(pool_size = 2)(drop2)
  flat2 =  Flatten()(pool2)
  
  conv31 = Conv1D(filter_no[2],kernel_size[2],activation = 'relu')(inp)
  conv32 = Conv1D(filter_no[2], kernel_size[2], activation = 'relu')(conv31)
  drop3 = Dropout(0.5)(conv32)
  pool3 = MaxPooling1D(pool_size = 2)(drop3)
  flat3 =  Flatten()(pool3)
  
  merged = concatenate([flat1, flat2, flat3])
  
  drop = Dropout(0.1)(merged)
  dense1 = Dense(32,activation = 'relu')(drop)
  dense2 = Dense(8,activation = 'relu')(dense1)
  output = Dense(6,activation = 'softmax')(dense2)
  
  
  model = Model(inp,output)
  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])
  from keras.utils.vis_utils import plot_model
#   plot_model(model, show_shapes=True, to_file='multichannel.png')
  
  
  print (model.summary())
  
  
  return model

checkpoint = keras.callbacks.ModelCheckpoint('model_{epoch:02d}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)
tensor_board = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')

X_train = np.load('X_train.npy')
X_test = np.load('X_test.npy')
y_train = np.load('y_train.npy')
y_test = np.load('y_test.npy')

kernel_size = [2,3,5]
filter_no = [64,32,16]
model = multi_headed_Models(kernel_size,filter_no,X_train.shape[1],X_train.shape[2])
history = model.fit(X_train,y_train,epochs = 10,batch_size=32,verbose = 1,callbacks = [checkpoint,tensor_board])

!pip install pydot

model.evaluate(X_test,y_test)



"""I will further work on doing this with the help of LSTM networks and a Combination of Convolutional Neural Networks and LSTM and along with that how to visualize the data and apply classical approaches to it also. Stay Tuned....."""

